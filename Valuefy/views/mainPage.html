<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="https://icon-library.com/images/icon-ai/icon-ai-3.jpg" type="image/x-icon">
    <link rel="stylesheet" href="mainPage.css">
    <title>Virtual Assistant - Task Manager</title>
</head>
<body>
    <div class="mainContent">
        <h1>Virtual Assistant - Task Manager</h1>
        <button id="startRecognition">Start Listening</button>
        <p id="textData">Listening for your command...</p>

        <div class="section">
            <h2>Extracted Tasks</h2>
            <ul id="tasks" class="editable">No tasks extracted yet.</ul>
        </div>

        <div class="section">
            <h2>Meeting Details</h2>
            <table id="meetingTable" class="meeting-table">
                <thead>
                    <tr>
                        <th>Date</th>
                        <th>Time</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td colspan="2" id="meetingDetails">No meeting details extracted yet.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="section">
            <h2>Meeting Summary</h2>
            <div id="summary" class="editable">No summary extracted yet.</div>
        </div>
    </div>

    <script>
        const start = document.getElementById('startRecognition');
        const textData = document.getElementById('textData');
        const tasks = document.getElementById('tasks');
        const meetingDetails = document.getElementById('meetingDetails');
        const summary = document.getElementById('summary');

        start.addEventListener('click', async () => {
            const recognition = new webkitSpeechRecognition();
            recognition.onresult = async ({ results }) => {
                const recognizedText = results[0][0].transcript;
                textData.textContent = recognizedText;

                try {
                    const response = await fetch('http://localhost:8000/virtualAssistant', {
                        method: 'POST',
                        body: JSON.stringify({ text: recognizedText }),
                        headers: { 'Content-Type': 'application/json' },
                    });

                    const data = await response.json();
                    tasks.innerHTML = "";
                    if (data.tasks && data.tasks !== "No tasks extracted.") {
                        data.tasks.split(", ").forEach(task => {
                            const li = document.createElement('li');
                            li.textContent = task;
                            tasks.appendChild(li);
                        });
                    } else {
                        tasks.textContent = "No tasks extracted yet.";
                    }

                    meetingDetails.textContent = data.meetingDetails || "No meeting details extracted yet.";

                    summary.textContent = data.summary || "No summary extracted yet.";
                } catch (error) {
                    console.error('Error:', error);
                }
            };
            recognition.start();
        });
    </script>
</body>
</html>